%                                                                 aa.dem
% AA vers. 8.2, LaTeX class for Astronomy & Astrophysics
% demonstration file
%                                                       (c) EDP Sciences
%-----------------------------------------------------------------------
%
%\documentclass[referee]{aa} % for a referee version
%\documentclass[onecolumn]{aa} % for a paper on 1 column  
%\documentclass[longauth]{aa} % for the long lists of affiliations 
%\documentclass[rnote]{aa} % for the research notes
%\documentclass[letter]{aa} % for the letters 
%\documentclass[bibyear]{aa} % if the references are not structured 
% according to the author-year natbib style

%
\documentclass{aa}  

%
\usepackage{graphicx}
\usepackage{txfonts}
%\usepackage[english]{babel}
%\usepackage[utf8]{inputenc}
%\usepackage{amsmath}	
%\usepackage{amssymb}
%\usepackage[colorinlistoftodos]{todonotes}
%\usepackage[square, numbers, comma, sort&compress]{natbib}
%\usepackage{algorithm}
%\usepackage[noend]{algpseudocode}
\usepackage{textcomp}
\usepackage{courier}
\usepackage{siunitx}
\usepackage{tabularx}
\usepackage{pdflscape}
%\usepackage{afterpage}
\usepackage{capt-of}% or use the larger `caption` package
\usepackage{multirow}
\usepackage{xcolor}
\usepackage{hyperref}
\def\memohr#1{\color{blue}$HR[${\bf #1}$]$ \color{black}}
\def\memorl#1{\color{gray}$RL[${\bf #1}$]$ \color{black}}


%\usepackage[options]{hyperref}
% To add links in your PDF file, use the package "hyperref"
% with options according to your LaTeX or PDFLaTeX drivers.
%
\begin{document} 


   \title{Using Langevin Based MCMC in Exoplanet Radial Velocity Surveys}

   \author{R. Leblanc
          \inst{1,3}
          \and
          H. Rein\inst{2,3}
          \and 
          E. B. Ford\inst{4,5,6}
          \and 
          B. E. Nelson\inst{4,5,6}
          }

   \institute{Department of Physics, University of Toronto, Toronto, Ontario M5S 1A7, Canada
   \and
   Department of Physical and Environmental Sciences, University of Toronto at Scarborough, Toronto, Ontario M1C 1A4, Canada
   \and 
   Department of Astronomy and Astrophysics, University of Toronto, Toronto, Ontario M5S 3H4, Canada
   \and 
   Center for Exoplanets and Habitable Worlds, The Pennsylvania State University 525 Davey Laboratory, University Park, PA, 16802, USA
   \and 
   Department of Astronomy and Astrophysics, The Pennsylvania State University 525 Davey Laboratory, University Park, PA, 16802, USA
   \and 
   Department of Astronomy, University of Florida, 211 Bryant Space Science Center, Gainesville, FL 32611, USA
             }

   \date{Draft - April 12 2017
       \memohr{A few general notes:\\
           1) AandA charges publication fees. MNRAS does not. For that reason I like MNRAS.\\
           2) Did you choose the abstract with subheadings on purpose? This kind of abstract is not universally appreciated in the community. \\
           3) In tex files, I find it useful to have one line per sentence. This makes it easy to move sentences around. It also helps git to make reasonable diffs.\\
       }
       \memorl{ RE: 1) I will move this work to an MNRAS template sometime later, this will also change the abstract form.
       }
   }

% \abstract{}{}{}{}{} 
% 5 {} token are mandatory
 
  \abstract
  % context heading (optional)
  % {} leave it empty if necessary  
   {In recent years, thousands of exoplanets of been discovered. 
Given this large amount of data, it is imperative that we optimize our ability to perform analysis. 
One of the techniques who are used to discover or analyze exoplanets are radial velocities surveys. 
In order to fit this type data, Markov Chain Monte Carlo (MCMC) methods are often applied.}
  % aims heading (mandatory)
   {In this work, we determine the effectiveness of langevin MCMC methods on radial velocity fitting. 
This algorithm produces less correlated samples but each proposal is more costly. 
We aim investigate to if this leads to an increased overall efficiency or not.}
  % methods heading (mandatory)
   {The performance we obtain is compared with the performance of two other standard MCMC, the affine invariant sampler and HMC.
We do this using time normalized effective sample size as our measure for a few test problems. 
\memohr{What does this have to do with methods? It also contradicts the results below.}
\memorl{I now clarify that the method we use to see if SMALA is better or worse is by comparing the MCMC with time normalized ESS as our measure.}
}
  % results heading (mandatory)
   {We observe that the computational costs associated with the second derivatives is too high when the dimensionality of the problem becomes large.
This costs outweighs some of the benefits from uncorrelated steps. Additionally, in high dimensional cases we see that our implemented langevin method has similar or worse autocorrelation times compared to the affine invariant sampler. This is most likely due to the complexity of the phase space.
\memohr{Isn't this the same as the last sentence?}
\memorl{There's a subtle difference which is discussed at length in the later parts. Not only does the computational cost go up, the effective sample size/autocorrelation time is practically the same in addition to that... Addressed by mentioning the complexity of the phase space.}.
}
  % conclusions heading (optional), leave it empty if necessary 
   {}

   \keywords{MCMC --
                Radial Velocity --
                Langevin Based Methods
               }

   \maketitle
%
%________________________________________________________________
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}
With thousands of exoplanets having already been discovered \cite{exoArchive}, many methods are used or combined to either refine our information or make yet newer discoveries. 
The two biggest contributors are transit measurements and radial velocity surveys. 
It may not always be possible to invest into more computing power to process this data. 
In order to process this large volume of data we need to use efficient Markov Chain Monte Carlo (MCMC) techniques. 
One route to speed up convergence of posteriors is to have an MCMC which makes better proposals. 
The idea is that by making these better proposals, we obtain uncorrelated samples, and thus require a smaller sample size to achieve the same effective sample size (ESS).

This is what Langevin MCMC methods do by using derivative information of the likelihood space. 
These types of techniques have never been implemented in an exoplanet context, and pose various technical challenges. 
These are discussed at length in section \ref{setup}. 
To test Langevin methods we require the derivative information, thus we need an analytical coordinate system described by \cite{Pl2009} such that these values are always defined. 
This calculation needs to be as efficient as possible, so we use an implementation of \texttt{Rebound}'s variational equations from \cite{Rein2016} to compute the $\chi^2$ likelihood derivative. 
Alongside this, we carefully selected the hyperparameters of the MCMC methods, as explained in section \ref{hyper}.

In this paper we compare our implementation with another MCMC by using the CPU time-normalized effective sample size (shortened to efficiency). 
We use 3 sample fitting problems to compare the algorithms, where we initialize the MCMC with best known, or true initial conditions. 
These have dimensions $N=1$, $N=4$, and $N=10$, ranging from the most simplistic case to using real data from a multi-planet system which is in resonance. 
These results are presented in section \ref{results}.

\memohr{This section reads really well!}
 
\section{Methods and Setup}\label{setup}
\subsection{MCMC Methods}
The Langevin method we chose in our implementation is the Simplified manifold Metropolis-Adjusted Langevin Algorithm (SMALA). 
The SMALA algorithm simplifies the general N-dimensional MALA algorithm by assuming the space is mostly flat and eliminating the terms in the proposal which account for the curvature of the space \citep{Girolami2011}.
\memohr{I'm not sure this is a correct description of SMALA. Clearly, we take into account the curvature of the likelihood space.}
\memorl{We look at the curvature of the likelihood function which lives inside a certain space but the curvature of the space it's in is not considered. Specifically, Girolami drops the Christoffel symbols which would be required for a generic Riemanian manifold, here we just assume the likelihood function lives in a Cartesian coordinate (uncurved coordinate for the space) so these terms are 0, hence `simplified'.}

With this simplification, the SMALA approach can be explained with a simple example. 
Given a Gaussian likelihood space, the Metropolis-Hastings algorithm will randomly wander through the distribution, favoring movement towards the maximum likelihood.
Rather than doing random proposals, we can make more effective proposals if we assume our likelihood function is approximately parabolic near the maximum. 
The SMALA method will use the first and second derivatives of the sampler to project a parabola and sample in close proximity of the maximum. 
\memohr{This sounds like we're just doing an interation of Newton's method. Need to mention that SMALA does not really jump to the maximum.}
\memorl{Addressed. We *sample* near the maximum.}
Depending on how good this parabolic approximation is, we can expect two benefits.
\begin{itemize}
\item Reaching the neighborhood of the maximum likelihood with fewer steps.
\item Highly uncorrelated samples since we make larger jumps.
\end{itemize}
These properties are shown very well in the sample problems of \cite{Girolami2011}. 
However, this benefit comes with the computational cost of calculating the gradient and Hessian of the likelihood function, which will scale in $\mathcal{O}(n^2)$, $n$ being the dimensionality of the problem. 
\memohr{define $n$}
\memorl{Addressed.}

We will compare the algorithm with the affine invariant sampling MCMC from \cite{Goodman2010} \memohr{Note that that FM2013 paper is mainly an implementation of the affine invariant sample. The only thing they add is splitting the sampler into two pools which allows for parallelization among other things. Should cite the original paper here.} \memorl{Good point, addressed.} and an implementation of Hamiltonian Monte Carlo (abbreviated as HMC) \citep{Duane1987}.
While we created our own python implementation of SMALA, the affine invariant MCMC has its own python package implementation known as EMCEE which we have used in our framework. 
This MCMC uses an ensemble of walkers to make linear proposals based on certain `moves'. 
In this work we use simple `stretch moves' which are described in full detail by \cite{Foreman-Mackey2013}. 
The other MCMC we compare with is the HMC which uses Hamiltonian mechanics to create new proposals. 
For a particular state an arbitrary velocity kick is given, drawn from a standard normal distribution. 
This will allow generating a new proposal based on how the state or `particle' will travel on the likelihood function as described by Hamiltonian mechanics. We implement a leapfrog method for integrating the state vector forward.

\subsection{Measures to Ensure Stability and Correctness}
Various steps were taken to maximize the numerical stability and usability of the MCMC for fitting exoplanets. Some were directly implemented into \texttt{Rebound}, while others were implemented at a higher level within our framework.

\subsubsection{\texttt{Rebound} Side}\label{analytical}
In the framework of traditional orbital elements certain derivatives be undefined. For example, the derivative of the argument of periapsis, $\omega$, is undefined when the eccentricity is zero. 
To avoid this we use the coordinates defined by \cite{Pl2009} which are trivially analytical since they use trigonometric functions, and are thus infinitely differentiable. 
In his paper, we find transformations which maps the traditional orbital elements unto an alternative set, $a, e, i, \omega, \Omega, M \to a, h, k, i_x, i_y, \lambda$ where $h$ and $k$ are the Lagrangian orbital elements, and the inclination and longitude are decomposed into $i_x$, $i_y$, and $\lambda$ gives the mean longitude. 
The equations describing this transformation can be found in the original paper. 
\memohr{This is basically just the chain rule. I don't think this deserves a discussion here.}
\memorl{Cleaned up a bit. We're good here.}

These coordinates come with a caveat, as all derivatives are undefined when considering a perfectly retrograde planet. However in such a case, the coordinate system can be reoriented or the planet can be offset by an arbitrarily small inclination.
\memohr{I don't understand this paragraph}
\memorl{Fixed. All derivatives break in the retrograde case, but in such a scenario the system can be reoriented.}

We combine these coordinates with the variational equations of \texttt{Rebound} to calculate the likelihood gradient and Hessian. 
These allow us to integrate the derivatives along with the dynamical system with very high numerical accuracy. 
These variational equations are initialized such to provide the response of the system with respect to the velocity component of the primary object. 
For example, a first order variation we could get would be $\frac{dv_x}{dh}$, and for a second order we could obtain $\frac{d^2v_x}{dhda}$. 
Given every one of these combinations we can build the $\chi^2$ Hessian with respect to the radial velocity measurements.

For our implementation in \texttt{Rebound}, if two planets come within two Hill radii of each other, the system is considered unstable and a likelihood of 0 is returned. 
We assign a likelihood of 0 since we assume that any planetary system which is observed today must necessarily be long-term stable. 
Unfortunately it is not computationally feasible to test the long-term stability of every sample, so we settle for this criteria even if the close encounter would not fully destabilize the system.
\memohr{I think the last to parasgrpahs can be summarized as follows: "If two planets come within two Hill radii of each other, the system is considered unstable and a likelihood of 0 is returned.}
\memorl{Shortened.}

\subsubsection{Python Side}
In the python front end we use a few tricks to improve the numerical stability. 
To handle very low likelihoods without numerical errors growing large, we work in log-likelihood. 
In addition to this, we avoid correlation bias between the semi-major axis and the mean longitude by making our integrations two-sided, centered on time $t=0$ \memohr{I don't think this is clear. Maybe reference Eric's paper where he used this}.
This correlation stems from the fact that a small change in period can allow `wiggle room' for a small change in phase, unless we allow this small perturbation to affect the data symmetrically.
Full details on this can be found in [...].
\memorl{Can't seem to locate the paper in which he employs this method..., I've checked the ones which mentioned RV in the title.. \href{http://astro.psu.edu/people/ebf11}{link to his homepage which has a link to his publications}}

In order to avoid instability during the inversion of the Hessian we take use a type of absolute value function on the eigenvalues. 
This forces the eigenvalues to be non-negative and above a certain threshold which is determined by a hyperparameter.
This function, called softabs, is described in \cite{softabs}.
\memohr{The 'soft absolute value of the eigenvalues' is not very clear. Try to be more precise.} 
\memorl{Addressed.}
This function gives the same behavior as an absolute value operator except near $0$ where it is smoothed out according to a scaling variable $\alpha$.
An eigenvalue of $0$ assume a value of $1/\alpha$ instead of $0$, which would be problematic, when we use this function.

\subsection{Hyperparameters}\label{hyper}
Each MCMC algorithm has a set of hyperparameters which must be determined for optimal performance. Here we describe the general procedure for selecting the hyperparameters for each MCMC.

One of the greatest assets of the affine invariant MCMC is the lack of hyperparameters that need to be set by the user and the ease of selection. 
Only two major hyperparameters need to be chosen, these are the number of walkers in the ensemble and the `aggressiveness of the stretch moves' (denoted as $a$ in the emcee documentation). 
\memohr{You first say that every MCMC has hyperparameters, then that the affine invarient sampler has none. Then finally you say that it has two! This can be simplified!}
\memohr{I'd be consistent and either call it affine invarient sapler or emcee. People might get lost if you switch back and forth.}
The performance of emcee increases with more walkers, for our test problems we have found 32 walkers to be sufficient as adding more did not give significant gains in performance. 
\memohr{Again, you can't say the opposite in two sentences that follow each other. Either the performance increases, or it does not increase. I know what you want to say, but it needs to be more precise and ideally more concise.}
The $a$ parameter was left at the recommended default value (a=2), we refer the reader to \cite{Foreman-Mackey2013} for a more detailed explanation on the significance of the parameter. 
\memohr{You start this section by saying that you describe how to select hyper parameters. But know you say you just stick to the previsouly used one! Again, I know what you've done and why you keep it fixed at 2, but you can't say the opposite to what you've said before}
\memohr{I'm sorry. By now this page looks like one of those PhD comics where the advisers gives back a draft to the student. It looks worse than it is! I'm pointing these things out because it is your first paper. Otherwise I would just correct it myself. But I want you to see what I would like to change and why.}
Another factor to consider is how the walkers are initialized. In general, initializing the ensemble as a small Gaussian sphere works remarkably well in almost every scenario. 
However, this approach may require a significant burn-in phase as the walkers expand to occupy the local shape of the likelihood space.
\memohr{In general the phrases 'works remarkably well' and 'in almost every scenario' are not very precise. Either say it works in all cases tested in this paper. Or way when it does not work. Having the information that it sometimes works and sometimes not, is not very useful by itself.}

For SMALA we need to specify a step scale $\epsilon$ and the softabs' $\alpha$ hyperparameter. 
The $\epsilon$ sets the `aggressiveness' of proposals and is used to fine-tune the acceptance rate. 
Geometrically, this corresponds to how far up the N-dimensional parabola we let the added `randomness' go. 
According to \cite{robert1998} the optimal acceptance rate tends towards $57\%$ as the dimensionality goes to infinity, thus we fix $\epsilon$ to give an acceptance rate in this limit.
The intuition for the $\alpha$ parameter is that it gives and maximum width to the proposal parabola. 
In the limiting case where this parameter is miscalculated and inhibits the MCMC's ability to make proposals, SMALA will behave like a Metropolis-Hastings MCMC. 
This is shown in Figure \ref{alpha}. 
\memohr{You need to introduce Figure 1 a bit more. What is shown, what is the test case, etc, basically what you have in the figure caption. The captions need to be very short and concise. }
While if we let $\alpha$ be too large, this may lead to numerical instabilities. 
In the context of exoplanets, both of the aforementioned parameters should approximately be of order unity.

\begin{figure}
\centering
\includegraphics[width=0.95\hsize]{alpha-1.png}
   \caption{This figure shows the effect of the alpha hyper-parameter on SMALA's sampling by considering 3 cases with increasing errors. 
Increasing the error on the data affects the sensitivity of the derivatives. 
This system contains one planet with only mass as a parameter, hence in this simple problem we expect the likelihood space to follow the parabolic approximation very closely. 
This is seen in cases one and two of this example. 
In case 3 where the error is greatest, the $\alpha$ parameter takes effect and limits the proposals. 
All three parabolas are generated from the Hessian at the true mass of the system.}
      \label{alpha}
\end{figure}

When using HMC we have three major hyperparameters to select. 
We must pick out a $\delta$ for the leapfrog steps, the number of leapfrog steps $L$ before testing a proposal state, and we need an appropriate mass matrix $M$ which corresponds the the scales and correlation of the parameters. 
A complete description can be found in chapter 5 of the MCMC Handbook \cite{1206.1901}. 
Due to the cost of evaluating the likelihood and its derivatives, $L=1$ gives the best efficiency score even when $N=1$. 
\memohr{Please state if you found this out or if this comes from some other work.}
The $\delta$ parameter is degenerate in the sense that changing it corresponds to the same effect as multiplying the mass matrix by some coefficient.
Hence, we chose a $\delta$ of order unity. 
For the selection of the matrix $M$ we use have opted to only specify the diagonal as doing all $N^2$ elements would be very time consuming.
The optimal acceptance rate for the HMC algorithm is determined by \cite{1001.4460}. 
In the limiting case of $L=1$ we obtain best results near an acceptance rate of $57\%$, in contrast with the optimal results for $L>1$ which are a few percent higher at $65\%$. 
\memohr{I'm confused. You just said L=1 has the best acceptance ratio?}
In addition to having an appropriate acceptance rate, we require the diagonal of $M$ to give autocorrelation rates which are approximately equal.
A good initial guess of the diagonal can be given by the inverse of the parameters. 
These masses are then tweaked according to the guidelines above.
\memohr{Again, this is just a bit too vague. What does tweaking mean here? And how about parameters such as angles? Or parameters which are initially set to 0 like the eccentricirty?}

Consider an example of $N=4$. 
Given the above procedure guidelines, say we would obtain an acceptance rate of $57\%$ with autocorrelations $AC_N = 12, 5, 2, 50$ with a first guess.
This would not constitute an appropriate MCMC run as one of the parameters will be greatly under determined due to inefficient sampling in that dimension. 
In contrast, if we would change the mass hyperparameters to give an acceptance rate of $54\%$ with $AC_N = 6, 7, 5, 8$, this would result in an appropriate instance of the MCMC with greater efficiency than the former. 
Namely, the efficiency is limited by the longest autocorrelation time (which gives the smallest effective sample size). 
\memohr{You define ESS later, but already use it here.}
Unfortunately, a certain amount of trial and error, and thus human labor, is required in order to find appropriate hyperparameters. 
One of the advantages of EMCEE and SMALA over HMC is the ease of selecting these hyperparameters.

Next we consider a short analysis of the local sensitivity of the hyperparameters for HMC and SMALA. 
This provides a rough idea to what order of magnitude the hyperparameters must be selected in practice. 
To quantify this we use a Monte Carlo approach and do 128 MCMC runs of an $N=4$ system of two planets (see Section \ref{n4section}) for both MCMC.
With each run a chosen hyperparameter is randomized. The measure of efficiency is explained in Section \ref{results}, however the most noteworthy point is that this score is a function of random variables. 
This measure will converge in the limit of infinite MCMC steps. 
For this Monte Carlo data, each run will have approximately 1000 autocorrelation times (as measured from near optimal performance) or alternatively, a few hundred effective samples. 
This corresponds to approximately 10000 steps for each SMALA run and 25000 steps for each HMC score evaluation. 
\memohr{I'm not sure what the last few sentences are about.}
\memohr{It's also a bit confusing to refer to section 3 and 3.2 here. Am I supposed to read section 3 now?}

In Figure \ref{sensfig} one can see the efficiency score as a function of hyperparameter value. 
In the upper portion of the plot we see SMALA, while the lower subplot shows the HMC performances. For SMALA we see performance smoothly decreasing as the hyperparameters receives larger perturbations from the optimal. 
However, we note that there are a few points new optimal $\epsilon$ which give low scores. 
These correspond to MCMC runs where the algorithm becomes entrapped in a part of phase space. 
These are rare occurrences when the MCMC fails to make good proposals for many steps in a row. 
For the HMC runs we observe that the hyperparameter is less smooth and appears to mimic a stepwise function on the left of the plot. 
This qualitatively shows that we may obtain non-trivial behavior when trying to optimize the HMC hyperparameters. 
As such, it can be somewhat challenging for a human \memohr{I guess it's challenging, period.} to find the best mass hyperparameters for HMC in high dimensional cases given increasing sensitivity. 
This is expected as the likelihood space becomes more complex.

\begin{figure}
\centering
\includegraphics[width=0.95\hsize]{sensitivity-1.png}
   \caption{This figure shows the hyperparameter sensitivity of SMALA and HMC for a 4 dimensional parameter space. 
We observe a few rare events where SMALA fails to perform optimally and see the HMC score exhibit non-trivial behavior in the left portion of the lower plot. 
The width of the bands give an estimation of the error for a few hundred effective samples.}
      \label{sensfig}
\end{figure}

\section{Results}\label{results}
\subsection{Simple Test, $N=1$}
We use this simple test case to verify the algorithms and introduce the time-normalized ESS which is used to compare the effectiveness of the MCMC.
This method is used in other comparative works such as \cite{Girolami2011, 1504.01418, Meyer2016, Lan2015} and many others. 
The total ESS if limited by the parameter which has the greatest autocorrelation time. Picking the smallest ESS among the $N$ parameters, we obtain $$ESS = \min_N\bigg( \frac{N}{(1+2\sum AC_k)}\bigg)$$ which is then normalized by the total CPU time in seconds. 

For this $N=1$ case we consider a planet with semi-major axis of $0.320$ and about $2.05$ Jupiter masses observed for a few orbits.
The generated data has errors of $10$ \si{\metre\per\second} with a small variance and was integrated for three and a half orbits.
The fitting parameter selected is the semi-major axis.

The initial conditions of the MCMC are the same as the true conditions. 
The resulting radial velocity curve is shown in Figure \ref{FigSimple}. 
In the upper part of the figure we see the initial conditions overlapped with traces of accepted proposals. 
Below we find the curve generated from taking the average of the resulting posterior samples, along with residuals.

\begin{figure}
\centering
\includegraphics[width=0.95\hsize]{rv1-1.png}
   \caption{This figure shows the results for the simple test case with SMALA. 
In the top panel we find the RV curve of the initial conditions in purple and 50 random trails generated from samples in the posterior. 
This shows the spread in how well the samples fit the curve. 
The middle and bottom subplot shows the average result after the burn in phase and the residuals of that fit, we can see that the initial conditions are well recovered.}
      \label{FigSimple}
\end{figure}

In this simple case 1-D case the SMALA algorithm strongly outperforms EMCEE and moderately outperforms HMC. 
This is clearly shown in the first row of Table \ref{Table1}. This is due to the low cost of calculating the first and second derivatives in this sample 1-D problem. 
The highly uncorrelated samples lead to a large ESS, this combined with the above makes the SMALA MCMC very efficient in the one dimension case, also surpassing HMC. All algorithms perfectly recover the original conditions and give identical distributions.

\begin{table}
\caption{MCMC Efficiency Results}             % title of Table
\label{Table1}      % is used to refer this table in the text
\centering                         
\resizebox{\columnwidth}{!}{
\begin{tabular}{c c c c c c}     
\hline\hline               
 & MCMC & Total Iterations & Minimum ESS & Total CPU-Time ($s$) & ESS/T \\    % table heading 
\hline                     
   \multirow{3}{*}{$N=1$} & EMCEE & 768000 & 25560 & 5783 & 4.42 \\ 
   & HMC & 320000 & 41004 & 4592 & 8.92 \\ 
   & SMALA& 320000 & 213222 & 7554 & 28.2 \\
\hline                                  
   \multirow{3}{*}{$N=4$} & EMCEE & 768000 & 14076 & 25233 & 0.558 \\      
   & HMC & 320000 & 16466 & 45827 & 0.360 \\ 
   & SMALA& 320000 & 58688 & 172170 & 0.341 \\
\hline                                  
   \multirow{3}{*}{$N=10$} & EMCEE & 768000 & 1325 & 39292 & 0.03372 \\      
   & HMC & 320000 & 406 & 123940 & 0.00272 \\ 
   & SMALA& 320000 & 241 & 1086615 & 0.00022 \\
\hline                                   
\end{tabular}
}
\end{table}

\subsection{2-Planet Case, $N=4$}\label{n4section}

In this problem we try fitting four parameters from two planets, we consider the semi-major axis and phase of each planet. 
As with the previous example, we start from the true parameters and run both MCMC for a few hundred thousand steps. 
The synthetic observations have 250 data points with errors centered on $10$ \si{\metre\per\second}. 
The data spans points are spread out over about a dozen orbits.

The resulting time normalized ESS are $0.558$, $0.360$, and $0.341$ for EMCEE, HMC, and SMALA respectively, as noted in Table \ref{Table1}. 
For four parameters, the SMALA algorithm will require a much longer runtime than EMCEE but will still generate posterior samples which are uncorrelated enough to compensate. 
The HMC algorithm shows the same behavior but with less intensity. For this case, the results of the algorithms quite similar and show approximately the same efficiency.


\subsection{Real Data: HD155358, $N=10$}

Now we consider a real data example using the RV data available for HD155358 from \cite{Robertson2012}. 
In this fit we solve for for ten parameters, for each planet we obtain: $a$, $m\, \sin i$\footnote{Since the $i_x$, $i_y$ parameters are excluded, we are effectively fitting the degenerate mass.}, $h$, $k$ and $\lambda$ as described in Section \ref{analytical}. 
The parameters obtained fall within errors of the original work by \cite{Robertson2012}.

In this scenario the EMCEE algorithm performs much better than SMALA and HMC, having a much higher efficiency by orders of magnitude. 
This is shown in the last row of Table \ref{Table1} with EMCEE giving $0.03372$ effective samples per second compared to HMC's $0.00272$ and SMALA's $0.00022$.

\begin{figure}
\centering
\includegraphics[width=0.95\hsize]{rv3-1.png}
   \caption{This figure shows the results for the HD155358 system. 
The uppermost plot shows the initial conditions of the system and the spread in the radial velocity curves generated from the posterior. 
The initial conditions used were provided by Robertson \cite{Robertson2012}. 
The radial velocity curve of the average parameters and residuals are presented below. 
The resulting parameters can be found in the appendix.}
      \label{FigHD}
\end{figure}

\section{Discussion \& Conclusion}
In general, when dealing with a full multi-planet system the SMALA algorithm does not perform well. 
Even in the smallest possible real case of $N=7$ parameters (mass \& 6 orbital parameters) SMALA will be outperformed by EMCEE \& HMC. 
The computational cost of calculating the metric is no longer beneficial at this dimensionality. 
When comparing the effective sample sizes, SMALA only produced less correlated samples in the cases of $N \leq 4$ parameters, while emcee performs better for the $N>4$ cases. 
We suspect that in addition to the computational cost, the complexity and nonlinearity of the high dimensional likelihood space limits the effectiveness of the MCMC, as it becomes very challenging to produce highly uncorrelated samples at a reasonable cost. 
To support this claim on nonlinearity, when we consider a system with two planets that strongly interact, we can observe these effects. 
This appears in some of the posterior samples, as shown by the trails in Figure \ref{FigHD}, we see these strong nonlinear effects on the left side as some RV trails extend above the $0.002$ mark. 
When the likelihood space exhibits such behavior, we might not expect the parabolic approximation to perform so well. 
As we get many samples in the phase space neighborhood of collisions, the likelihood manifold becomes curved and distorted. 
This effect may create a minimum autocorrelation threshold which is reached by the SMALA MCMC. 
One possible solution to this dilemma would be to acquire data with smaller errors, this geometrically corresponds to tightening the likelihood well, as shown in Figure \ref{alpha}.  
This would make the space near the maximum adhere more closely to a parabolic approximation, and prevent the MCMC from wandering in the regions of phase space where collisions and nonlinear effects are likely. 
However, even with advances in RV instrumentation, it unlikely feasible to obtain errors small enough to resolve these issues via sharper, more `parabola-shaped' likelihoods. 
Even if we do obtain such small errors, the computational cost will most likely dominate and EMCEE will be the most efficient MCMC.

To summarize, the costs of generating an accurate Hessians outweighs the benefits of highly uncorrelated steps at high dimensionality. 
The EMCEE algorithm will outperform SMALA by orders of magnitude in large multi-planet systems encountered in practice. 
The dimensionality threshold where the affine invariant MCMC and the SMALA MCMC perform comparably is around $N = 4$, meaning that even for a single planet system EMCEE or HMC will be more efficient.

In future works we will consider hybrid MCMC which use combinations of  EMCEE, HMC, and SMALA steps to achieve maximal efficiency by giving each MCMC specific combinations parameter. 
Another example for potential improvements would be to consider Gibbs-SMALA or maybe planet-wise blocked Gibbs sampler approach which could speed up the algorithm. 
An additional pursuit to improve the speed of analysis might be to use the analytical solution to Kepler's equations in our proposals instead of variational equations, this would be much more computationally cheap. 
A consequence of this approach would be the introduction of errors in the derivative, as N-body effects would not be considered. 
Another modification to consider would be the ALSMALA algorithm which uses partial metric updates \cite{1608.07986}. 
Using an inaccurate metric will lead to more correlated samples, however there may exist an optimum point where overall performance is enhanced.

\begin{acknowledgements}
	This research was funded by NSERC Discovery Grant RGPIN-2014-04553. 
Computations were performed on the GPC supercomputer at the SciNet HPC Consortium. 
SciNet is funded by: the Canada Foundation for Innovation under the auspices of Compute Canada; the Government of Ontario; Ontario Research Fund - Research Excellence; and the University of Toronto.
\end{acknowledgements}


%-------------------------------------------------------------------
%\pagebreak

\bibliographystyle{apa}
\bibliography{Bibliography}

\begin{appendix} 

\begin{sidewaystable*}
\caption{MCMC Average Resulting Parameters with 95\% Credible Intervals}\label{Table4}
\centering
\begin{tabular}{c c c c c c c c c c c c}        % centered columns (4 columns)
\hline\hline                 % inserts double horizontal lines
 & MCMC & $a_0$ & $h_0$ & $k_0$ & $m_0$ ($10^{-4}$) & $\lambda_0$ & $a_1$ & $h_1$ & $k_1$ & $m_1$ ($10^{-4}$) & $\lambda_1$ \\    % table heading 
\hline                        % inserts single horizontal line
   \rule{0pt}{4ex}  \multirow{5}{*}{$N=1$} & EMCEE & $0.3192^{+0.0071}_{-0.0076}$ & - & - & - & - & - & - & - & - & - \\
   \rule{0pt}{4ex} & SMALA &  $0.3193^{+0.0071}_{-0.0076}$ & - & - & - & - & - & - & - & - & -\\
    \rule{0pt}{4ex} & HMC &  $0.3194^{+0.0048}_{-0.0051}$ & - & - & - & - & - & - & - & - & -\\
   \rule{0pt}{4ex}  \multirow{5}{*}{$N=4$} & EMCEE & $0.3198^{+0.0026}_{-0.0026}$ & - & - & - & $1.711^{+0.187}_{-0.184}$ & $0.5817^{+0.0244}_{-0.0221}$ & - & - & - & $1.031^{+0.396}_{-0.394}$ \\
   \rule{0pt}{4ex} & SMALA &  $0.3199^{+0.0026}_{-0.0026}$ & - & - & - & $1.712^{+0.186}_{-0.184}$ & $0.5817^{+0.0244}_{-0.0221}$ & - & - & - & $1.030^{+0.390}_{-0.388}$\\
    \rule{0pt}{4ex} & HMC &  $0.3199^{+0.0019}_{-0.0019}$ & - & - & - & $1.711^{+0.087}_{-00186}$ & $0.5808^{+0.0156}_{-0.0149}$ & - & - & - & $1.035^{+0.152}_{-0.159}$\\
   %\rule{0pt}{3ex}
   \rule{0pt}{4ex} \multirow{5}{*}{$N=10$} & EMCEE & $0.6586^{+0.0087}_{-0.0089}$ & $-0.11^{+0.35}_{-0.31}$ & $-0.12^{+0.31}_{-0.32}$ & $8.1^{+3.3}_{-3.4}$ & $4.52^{+0.55}_{-0.50}$ & $1.046^{+0.024}_{-0.026}$ & $-0.14^{+0.52}_{-0.45}$ & $-0.05^{+0.50}_{-0.48}$ & $8.5^{+3.5}_{-3.2}$ & $1.54^{+0.62}_{-0.58}$ \\
   \rule{0pt}{4ex} & SMALA & $0.6508^{+0.0077}_{-0.0076}$ & $-0.14^{+0.31}_{-0.30}$ & $-0.10^{+0.30}_{-0.27}$ & $8.2^{+3.4}_{-3.0}$ & $4.54^{+0.54}_{-0.52}$ & $1.046^{+0.022}_{-0.026}$ & $-0.13^{+0.52}_{-0.42}$ & $-0.04^{+0.47}_{-0.46}$ & $8.6^{+3.5}_{-3.2}$ & $1.52^{+0.60}_{-0.55}$\\
   \rule{0pt}{4ex} & HMC & $0.6583^{+0.0074}_{-0.0067}$ & $-0.14^{+0.22}_{-0.19}$ & $-0.10^{+0.16}_{-0.15}$ & $8.4^{+3.0}_{-2.6}$ & $4.49^{+0.41}_{-1.46}$ & $1.046^{+0.020}_{-0.024}$ & $-0.12^{+0.39}_{-0.36}$ & $-0.04^{+0.36}_{-0.64}$ & $8.6^{+2.6}_{-2.4}$ & $1.51^{+0.44}_{-0.37}$\\
   %\rule{0pt}{3ex}
\hline  
\end{tabular}
\end{sidewaystable*}

\end{appendix}

%\pagebreak
%\newpage

\end{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Examples for figures using graphicx
A guide "Using Imported Graphics in LaTeX2e"  (Keith Reckdahl)
is available on a lot of LaTeX public servers or ctan mirrors.
The file is : epslatex.pdf 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%_____________________________________________________________
%                 A figure as large as the width of the column
%-------------------------------------------------------------
   \begin{figure}
   \centering
   \includegraphics[width=\hsize]{empty.eps}
      \caption{Vibrational stability equation of state
               $S_{\mathrm{vib}}(\lg e, \lg \rho)$.
               $>0$ means vibrational stability.
              }
         \label{FigVibStab}
   \end{figure}
%
%_____________________________________________________________
%                                    One column rotated figure
%-------------------------------------------------------------
   \begin{figure}
   \centering
   \includegraphics[angle=-90,width=3cm]{empty.eps}
      \caption{Vibrational stability equation of state
               $S_{\mathrm{vib}}(\lg e, \lg \rho)$.
               $>0$ means vibrational stability.
              }
         \label{FigVibStab}
   \end{figure}
%
%_____________________________________________________________
%                        Figure with caption on the right side 
%-------------------------------------------------------------
   \begin{figure}
   \sidecaption
   \includegraphics[width=3cm]{empty.eps}
      \caption{Vibrational stability equation of state
               $S_{\mathrm{vib}}(\lg e, \lg \rho)$.
               $>0$ means vibrational stability.
              }
         \label{FigVibStab}
   \end{figure}
%
%_____________________________________________________________
%
%_____________________________________________________________
%                                Figure with a new BoundingBox 
%-------------------------------------------------------------
   \begin{figure}
   \centering
   \includegraphics[bb=10 20 100 300,width=3cm,clip]{empty.eps}
      \caption{Vibrational stability equation of state
               $S_{\mathrm{vib}}(\lg e, \lg \rho)$.
               $>0$ means vibrational stability.
              }
         \label{FigVibStab}
   \end{figure}
%
%_____________________________________________________________
%
%_____________________________________________________________
%                                      The "resizebox" command 
%-------------------------------------------------------------
   \begin{figure}
   \resizebox{\hsize}{!}
            {\includegraphics[bb=10 20 100 300,clip]{empty.eps}
      \caption{Vibrational stability equation of state
               $S_{\mathrm{vib}}(\lg e, \lg \rho)$.
               $>0$ means vibrational stability.
              }
         \label{FigVibStab}
   \end{figure}
%
%______________________________________________________________
%
%_____________________________________________________________
%                                             Two column Figure 
%-------------------------------------------------------------
   \begin{figure*}
   \resizebox{\hsize}{!}
            {\includegraphics[bb=10 20 100 300,clip]{empty.eps}
      \caption{Vibrational stability equation of state
               $S_{\mathrm{vib}}(\lg e, \lg \rho)$.
               $>0$ means vibrational stability.
              }
         \label{FigVibStab}
   \end{figure*}
%
%______________________________________________________________
%
%_____________________________________________________________
%                                             Simple A&A Table
%_____________________________________________________________
%
\begin{table}
\caption{Nonlinear Model Results}             % title of Table
\label{table:1}      % is used to refer this table in the text
\centering                          % used for centering table
\begin{tabular}{c c c c}        % centered columns (4 columns)
\hline\hline                 % inserts double horizontal lines
HJD & $E$ & Method\#2 & Method\#3 \\    % table heading 
\hline                        % inserts single horizontal line
   1 & 50 & $-837$ & 970 \\      % inserting body of the table
   2 & 47 & 877    & 230 \\
   3 & 31 & 25     & 415 \\
   4 & 35 & 144    & 2356 \\
   5 & 45 & 300    & 556 \\ 
\hline                                   %inserts single line
\end{tabular}
\end{table}
%
%_____________________________________________________________
%                                             Two column Table 
%_____________________________________________________________
%
\begin{table*}
\caption{Nonlinear Model Results}             
\label{table:1}      
\centering          
\begin{tabular}{c c c c l l l }     % 7 columns 
\hline\hline       
                      % To combine 4 columns into a single one 
HJD & $E$ & Method\#2 & \multicolumn{4}{c}{Method\#3}\\ 
\hline                    
   1 & 50 & $-837$ & 970 & 65 & 67 & 78\\  
   2 & 47 & 877    & 230 & 567& 55 & 78\\
   3 & 31 & 25     & 415 & 567& 55 & 78\\
   4 & 35 & 144    & 2356& 567& 55 & 78 \\
   5 & 45 & 300    & 556 & 567& 55 & 78\\
\hline                  
\end{tabular}
\end{table*}
%
%-------------------------------------------------------------
%                                          Table with notes 
%-------------------------------------------------------------
%
% A single note
\begin{table}
\caption{\label{t7}Spectral types and photometry for stars in the
  region.}
\centering
\begin{tabular}{lccc}
\hline\hline
Star&Spectral type&RA(J2000)&Dec(J2000)\\
\hline
69           &B1\,V     &09 15 54.046 & $-$50 00 26.67\\
49           &B0.7\,V   &*09 15 54.570& $-$50 00 03.90\\
LS~1267~(86) &O8\,V     &09 15 52.787&11.07\\
24.6         &7.58      &1.37 &0.20\\
\hline
LS~1262      &B0\,V     &09 15 05.17&11.17\\
MO 2-119     &B0.5\,V   &09 15 33.7 &11.74\\
LS~1269      &O8.5\,V   &09 15 56.60&10.85\\
\hline
\end{tabular}
\tablefoot{The top panel shows likely members of Pismis~11. The second
panel contains likely members of Alicante~5. The bottom panel
displays stars outside the clusters.}
\end{table}
%
% More notes
%
\begin{table}
\caption{\label{t7}Spectral types and photometry for stars in the
  region.}
\centering
\begin{tabular}{lccc}
\hline\hline
Star&Spectral type&RA(J2000)&Dec(J2000)\\
\hline
69           &B1\,V     &09 15 54.046 & $-$50 00 26.67\\
49           &B0.7\,V   &*09 15 54.570& $-$50 00 03.90\\
LS~1267~(86) &O8\,V     &09 15 52.787&11.07\tablefootmark{a}\\
24.6         &7.58\tablefootmark{1}&1.37\tablefootmark{a}   &0.20\tablefootmark{a}\\
\hline
LS~1262      &B0\,V     &09 15 05.17&11.17\tablefootmark{b}\\
MO 2-119     &B0.5\,V   &09 15 33.7 &11.74\tablefootmark{c}\\
LS~1269      &O8.5\,V   &09 15 56.60&10.85\tablefootmark{d}\\
\hline
\end{tabular}
\tablefoot{The top panel shows likely members of Pismis~11. The second
panel contains likely members of Alicante~5. The bottom panel
displays stars outside the clusters.\\
\tablefoottext{a}{Photometry for MF13, LS~1267 and HD~80077 from
Dupont et al.}
\tablefoottext{b}{Photometry for LS~1262, LS~1269 from
Durand et al.}
\tablefoottext{c}{Photometry for MO2-119 from
Mathieu et al.}
}
\end{table}
%
%-------------------------------------------------------------
%                                       Table with references 
%-------------------------------------------------------------
%
\begin{table*}[h]
 \caption[]{\label{nearbylistaa2}List of nearby SNe used in this work.}
\begin{tabular}{lccc}
 \hline \hline
  SN name &
  Epoch &
 Bands &
  References \\
 &
  (with respect to $B$ maximum) &
 &
 \\ \hline
1981B   & 0 & {\it UBV} & 1\\
1986G   &  $-$3, $-$1, 0, 1, 2 & {\it BV}  & 2\\
1989B   & $-$5, $-$1, 0, 3, 5 & {\it UBVRI}  & 3, 4\\
1990N   & 2, 7 & {\it UBVRI}  & 5\\
1991M   & 3 & {\it VRI}  & 6\\
\hline
\noalign{\smallskip}
\multicolumn{4}{c}{ SNe 91bg-like} \\
\noalign{\smallskip}
\hline
1991bg   & 1, 2 & {\it BVRI}  & 7\\
1999by   & $-$5, $-$4, $-$3, 3, 4, 5 & {\it UBVRI}  & 8\\
\hline
\noalign{\smallskip}
\multicolumn{4}{c}{ SNe 91T-like} \\
\noalign{\smallskip}
\hline
1991T   & $-$3, 0 & {\it UBVRI}  &  9, 10\\
2000cx  & $-$3, $-$2, 0, 1, 5 & {\it UBVRI}  & 11\\ %
\hline
\end{tabular}
\tablebib{(1)~\citet{branch83};
(2) \citet{phillips87}; (3) \citet{barbon90}; (4) \citet{wells94};
(5) \citet{mazzali93}; (6) \citet{gomez98}; (7) \citet{kirshner93};
(8) \citet{patat96}; (9) \citet{salvo01}; (10) \citet{branch03};
(11) \citet{jha99}.
}
\end{table}
%_____________________________________________________________
%                      A rotated Two column Table in landscape  
%-------------------------------------------------------------
\begin{sidewaystable*}
\caption{Summary for ISOCAM sources with mid-IR excess 
(YSO candidates).}\label{YSOtable}
\centering
\begin{tabular}{crrlcl} 
\hline\hline             
ISO-L1551 & $F_{6.7}$~[mJy] & $\alpha_{6.7-14.3}$ 
& YSO type$^{d}$ & Status & Comments\\
\hline
  \multicolumn{6}{c}{\it New YSO candidates}\\ % To combine 6 columns into a single one
\hline
  1 & 1.56 $\pm$ 0.47 & --    & Class II$^{c}$ & New & Mid\\
  2 & 0.79:           & 0.97: & Class II ?     & New & \\
  3 & 4.95 $\pm$ 0.68 & 3.18  & Class II / III & New & \\
  5 & 1.44 $\pm$ 0.33 & 1.88  & Class II       & New & \\
\hline
  \multicolumn{6}{c}{\it Previously known YSOs} \\
\hline
  61 & 0.89 $\pm$ 0.58 & 1.77 & Class I & \object{HH 30} & Circumstellar disk\\
  96 & 38.34 $\pm$ 0.71 & 37.5& Class II& MHO 5          & Spectral type\\
\hline
\end{tabular}
\end{sidewaystable*}
%_____________________________________________________________
%                      A rotated One column Table in landscape  
%-------------------------------------------------------------
\begin{sidewaystable}
\caption{Summary for ISOCAM sources with mid-IR excess 
(YSO candidates).}\label{YSOtable}
\centering
\begin{tabular}{crrlcl} 
\hline\hline             
ISO-L1551 & $F_{6.7}$~[mJy] & $\alpha_{6.7-14.3}$ 
& YSO type$^{d}$ & Status & Comments\\
\hline
  \multicolumn{6}{c}{\it New YSO candidates}\\ % To combine 6 columns into a single one
\hline
  1 & 1.56 $\pm$ 0.47 & --    & Class II$^{c}$ & New & Mid\\
  2 & 0.79:           & 0.97: & Class II ?     & New & \\
  3 & 4.95 $\pm$ 0.68 & 3.18  & Class II / III & New & \\
  5 & 1.44 $\pm$ 0.33 & 1.88  & Class II       & New & \\
\hline
  \multicolumn{6}{c}{\it Previously known YSOs} \\
\hline
  61 & 0.89 $\pm$ 0.58 & 1.77 & Class I & \object{HH 30} & Circumstellar disk\\
  96 & 38.34 $\pm$ 0.71 & 37.5& Class II& MHO 5          & Spectral type\\
\hline
\end{tabular}
\end{sidewaystable}
%
%_____________________________________________________________
%                              Table longer than a single page  
%-------------------------------------------------------------
% All long tables will be placed automatically at the end, after 
%                                        \end{thebibliography}
%
\begin{longtab}
\begin{longtable}{lllrrr}
\caption{\label{kstars} Sample stars with absolute magnitude}\\
\hline\hline
Catalogue& $M_{V}$ & Spectral & Distance & Mode & Count Rate \\
\hline
\endfirsthead
\caption{continued.}\\
\hline\hline
Catalogue& $M_{V}$ & Spectral & Distance & Mode & Count Rate \\
\hline
\endhead
\hline
\endfoot
%%
Gl 33    & 6.37 & K2 V & 7.46 & S & 0.043170\\
Gl 66AB  & 6.26 & K2 V & 8.15 & S & 0.260478\\
Gl 68    & 5.87 & K1 V & 7.47 & P & 0.026610\\
         &      &      &      & H & 0.008686\\
Gl 86 
\footnote{Source not included in the HRI catalog. See Sect.~5.4.2 for details.}
         & 5.92 & K0 V & 10.91& S & 0.058230\\
\end{longtable}
\end{longtab}
%
%_____________________________________________________________
%                              Table longer than a single page
%                                             and in landscape 
%  In the preamble, use:       \usepackage{lscape}
%-------------------------------------------------------------
% All long tables will be placed automatically at the end, after
%                                        \end{thebibliography}
%
\begin{longtab}
\begin{landscape}
\begin{longtable}{lllrrr}
\caption{\label{kstars} Sample stars with absolute magnitude}\\
\hline\hline
Catalogue& $M_{V}$ & Spectral & Distance & Mode & Count Rate \\
\hline
\endfirsthead
\caption{continued.}\\
\hline\hline
Catalogue& $M_{V}$ & Spectral & Distance & Mode & Count Rate \\
\hline
\endhead
\hline
\endfoot
%%
Gl 33    & 6.37 & K2 V & 7.46 & S & 0.043170\\
Gl 66AB  & 6.26 & K2 V & 8.15 & S & 0.260478\\
Gl 68    & 5.87 & K1 V & 7.47 & P & 0.026610\\
         &      &      &      & H & 0.008686\\
Gl 86
\footnote{Source not included in the HRI catalog. See Sect.~5.4.2 for details.}
         & 5.92 & K0 V & 10.91& S & 0.058230\\
\end{longtable}
\end{landscape}
\end{longtab}
%
% Online Material
%_____________________________________________________________
%        Online appendices have to be placed at the end, after
%                                        \end{thebibliography}
%-------------------------------------------------------------
\end{thebibliography}

\Online

\begin{appendix} %First online appendix
\section{Background galaxy number counts and shear noise-levels}
Because the optical images used in this analysis...

\begin{figure*}
\centering
\includegraphics[width=16.4cm,clip]{1787f24.ps}
\caption{Plotted above...}
\label{appfig}
\end{figure*}

Because the optical images...
\end{appendix}

\begin{appendix} %Second online appendix
These studies, however, have faced...
\end{appendix}

\end{document}
%
%_____________________________________________________________
%        Some tables or figures are in the printed version and
%                      some are only in the electronic version
%-------------------------------------------------------------
%
% Leave all the tables or figures in the text, at their right place 
% and use the commands \onlfig{} and \onltab{}. These elements
% will be automatically placed at the end, in the section
% Online material.

\documentclass{aa}
...
\begin{document}
text of the paper...
\begin{figure*}%f1
\includegraphics[width=10.9cm]{1787f01.eps}
\caption{Shown in greyscale is a...}
\label{cl12301}}
\end{figure*}
...
from the intrinsic ellipticity distribution.
% Figure 2 available electronically only
\onlfig{
\begin{figure*}%f2
\includegraphics[width=11.6cm]{1787f02.eps}
\caption {Shown in greyscale...}
\label{cl1018}
\end{figure*}
}

% Figure 3 available electronically only
\onlfig{
\begin{figure*}%f3
\includegraphics[width=11.2cm]{1787f03.eps}
\caption{Shown in panels...}
\label{cl1059}
\end{figure*}
}

\begin{figure*}%f4
\includegraphics[width=10.9cm]{1787f04.eps}
\caption{Shown in greyscale is...}
\label{cl1232}}
\end{figure*}

\begin{table}%t1
\caption{Complexes characterisation.}\label{starbursts}
\centering
\begin{tabular}{lccc}
\hline \hline
Complex & $F_{60}$ & 8.6 &  No. of  \\
...
\hline
\end{tabular}
\end{table}
The second method produces...

% Figure 5 available electronically only
\onlfig{
\begin{figure*}%f5
\includegraphics[width=11.2cm]{1787f05.eps}
\caption{Shown in panels...}
\label{cl1238}}
\end{figure*}
}

As can be seen, in general the deeper...
% Table 2 available electronically only
\onltab{
\begin{table*}%t2
\caption{List of the LMC stellar complexes...}\label{Properties}
\centering
\begin{tabular}{lccccccccc}
\hline  \hline
Stellar & RA & Dec & ...
...
\hline
\end{tabular}
\end{table*}
}

% Table 3 available electronically only
\onltab{
\begin{table*}%t3
\caption{List of the derived...}\label{IrasFluxes}
\centering
\begin{tabular}{lcccccccccc}
\hline \hline
Stellar & $f12$ & $L12$ &...
...
\hline
\end{tabular}
\end{table*}
}
%
%-------------------------------------------------------------
%     For the online material, table longer than a single page
%                 In the preamble for landscape case, use : 
%                                          \usepackage{lscape}
%-------------------------------------------------------------
\documentclass{aa}
\usepackage[varg]{txfonts}
\usepackage{graphicx}
\usepackage{lscape}

\begin{document}
text of the paper
% Table will be print automatically at the end, in the section Online material.
\onllongtab{
\begin{longtable}{lrcrrrrrrrrl}
\caption{Line data and abundances ...}\\
\hline
\hline
Def & mol & Ion & $\lambda$ & $\chi$ & $\log gf$ & N & e &  rad & $\delta$ & $\delta$ 
red & References \\
\hline
\endfirsthead
\caption{Continued.} \\
\hline
Def & mol & Ion & $\lambda$ & $\chi$ & $\log gf$ & B & C &  rad & $\delta$ & $\delta$ 
red & References \\
\hline
\endhead
\hline
\endfoot
\hline
\endlastfoot
A & CH & 1 &3638 & 0.002 & $-$2.551 &  &  &  & $-$150 & 150 &  Jorgensen et al. (1996) \\                    
\end{longtable}
}% End onllongtab

% Or for landscape, large table:

\onllongtab{
\begin{landscape}
\begin{longtable}{lrcrrrrrrrrl}
...
\end{longtable}
\end{landscape}
}% End onllongtab
